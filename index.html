<!DOCTYPE html>
<html lang="ja">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<title>顔認識</title>
<style>
  /* video 要素の上に canvas 要素をオーバーレイするための CSS */
  #container {              /* コンテナ用の div について */
    position: relative;     /* 座標指定を相対値指定にする */
  }
  #video {                  /* カメラ映像を流す video について */
    transform: scaleX(-1);  /* 左右反転させる */
  }
  #canvas {                 /* 描画用の canvas について */
    transform: scaleX(-1);  /* 左右反転させる */
    position: absolute;     /* 座標指定を絶対値指定にして */
    left: 0;                /* X座標を0に */
    top: 0;                 /* Y座標を0に */
  }
</style>
</head>

<body>
  <div id="container">  <!-- video の上に canvas をオーバーレイするための div 要素 -->
    <video id="video" width="400" height="300" autoplay></video>  <!-- カメラ映像を流す video -->
    <canvas id="canvas" width="400" height="300"></canvas>        <!-- 重ねて描画する canvas -->
  </div>
  <div id="dat"></div>  <!-- データ表示用 div 要素 -->
   
  <!-- clmtrackr 関連ファイルの読み込み -->
  <script src="clmtrackr.js"></script>          <!-- clmtrackr のメインライブラリの読み込み -->
  <script src="model_pca_20_svm_emotion.js"></script>   <!-- ★顔モデル（※1）の読み込み -->
  <script src="emotionClassifier.js"></script>  <!-- ★感情を分類する外部関数の読み込み -->
  <script src="emotionModel.js"></script>       <!-- ★感情モデル（※2）の読み込み -->
  
  // PubNubどうにかしたい
  <script src="app.js"></script>
  <script src="https://cdn.pubnub.com/sdk/javascript/pubnub.4.28.2.min.js"></script>
  <script src="https://code.jquery.com/jquery-2.1.4.min.js"></script>
  <script>
  pubnub = new PubNub({
        publishKey : 'pub-c-756ff5ef-8a21-474b-ad11-ce812a9ea63b',
        subscribeKey : 'sub-c-85e7f614-ba7c-11ea-a44f-6e05387a1df4',
        uuid: "myUniqueUUID"
    });

  // もろもろの準備
  var video = document.getElementById("video");           // video 要素を取得
  var canvas = document.getElementById("canvas");         // canvas 要素の取得
  var context = canvas.getContext("2d");                  // canvas の context の取得
   
  // getUserMedia によるカメラ映像の取得
  var media = navigator.mediaDevices.getUserMedia({       // メディアデバイスを取得
    video: {facingMode: "user"},                          // カメラの映像を使う（スマホならインカメラ）
    audio: false                                          // マイクの音声は使わない
  });
  media.then((stream) => {                                // メディアデバイスが取得できたら
    video.srcObject = stream;                             // video 要素にストリームを渡す
  });
   
  // clmtrackr の開始
  var tracker = new clm.tracker();  // tracker オブジェクトを作成
  tracker.init(pModel);             // tracker を所定のフェイスモデル（※1）で初期化
  tracker.start(video);             // video 要素内でフェイストラッキング開始
   
  // 感情分類の開始
  var classifier = new emotionClassifier();               // ★emotionClassifier オブジェクトを作成
  classifier.init(emotionModel);                          // ★classifier を所定の感情モデル（※2）で初期化
   
  // 描画ループ
  function drawLoop() {
    requestAnimationFrame(drawLoop);                      // drawLoop 関数を繰り返し実行
    var positions = tracker.getCurrentPosition();         // 顔部品の現在位置の取得
    var parameters = tracker.getCurrentParameters();      // ★現在の顔のパラメータを取得
    var emotion = classifier.meanPredict(parameters);     // ★そのパラメータから感情を推定して emotion に結果を入れる
    showEmotionData(emotion);                             // ★感情データを表示
    context.clearRect(0, 0, canvas.width, canvas.height); // canvas をクリア
    tracker.draw(canvas);                                 // canvas にトラッキング結果を描画
    if(emotion[5].value > 0.5){
       // publish('on');    
       var publishConfig = {
            channel : "led-onoff",
            message: "on"
        }
        pubnub.publish(publishConfig, function(status, response) {
            console.log(status, response);
        })
      }
    if(emotion[5].value < 0.5){
       // publish('off');
       var publishConfig = {
            channel : "led-onoff",
            message: "off"
        }
        pubnub.publish(publishConfig, function(status, response) {
            console.log(status, response);
        })
    	} 
  }
  drawLoop();                                             // drawLoop 関数をトリガー
   
  // ★感情データの表示
  function showEmotionData(emo) {
    var str ="";                                          // データの文字列を入れる変数
    for(var i = 0; i < emo.length; i++) {                 // 全ての感情（6種類）について
      str += emo[i].emotion + ": "                        // 感情名
           + emo[i].value.toFixed(1) + "<br>";            // 感情の程度（小数第一位まで）
    }
    var dat = document.getElementById("dat");             // データ表示用div要素の取得
    dat.innerHTML = str;                                  // データ文字列の表示
  }
  </script>

</body>
</html>